{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import dlib\n",
    "from scipy.spatial import distance as dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eye_aspect_ratio(eye):\n",
    "    # compute the euclidean distance between the vertical eye landmarks\n",
    "    A = dist.euclidean(eye[1], eye[5])\n",
    "    B = dist.euclidean(eye[2], eye[4])\n",
    "\n",
    "    # compute the euclidean distance between the horizontal eye landmarks\n",
    "    C = dist.euclidean(eye[0], eye[3])\n",
    "\n",
    "    # compute the EAR\n",
    "    ear = (A + B) / (2 * C)\n",
    "    return ear\n",
    "\n",
    "# to detect the facial region\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('/home/mini/shape_predictor_68_face_landmarks.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, render_template, Response,jsonify\n",
    "app = Flask(__name__)\n",
    "\n",
    "\n",
    "\n",
    "cap=cv2.VideoCapture(0) #0 for 1st webcam\n",
    "font = cv2.FONT_HERSHEY_PLAIN\n",
    "starting_time= time.time()\n",
    "\n",
    "def gen_frames():\n",
    "    JAWLINE_POINTS = list(range(0, 17))\n",
    "    RIGHT_EYEBROW_POINTS = list(range(17, 22))\n",
    "    LEFT_EYEBROW_POINTS = list(range(22, 27))\n",
    "    NOSE_POINTS = list(range(27, 36))\n",
    "    RIGHT_EYE_POINTS = list(range(36, 42))\n",
    "    LEFT_EYE_POINTS = list(range(42, 48))\n",
    "    MOUTH_OUTLINE_POINTS = list(range(48, 61))\n",
    "    MOUTH_INNER_POINTS = list(range(61, 68))\n",
    "\n",
    "    EYE_AR_THRESH = 0.22\n",
    "    EYE_AR_CONSEC_FRAMES = 3\n",
    "    EAR_AVG = 0\n",
    "\n",
    "    COUNTER = 0\n",
    "    TOTAL = 0\n",
    "    \n",
    "    \n",
    "    while True:\n",
    "        _,frame= cap.read() # \n",
    "        #frame_id+=1\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        rects = detector(gray, 0)\n",
    "        for rect in rects:\n",
    "            x = rect.left()\n",
    "            y = rect.top()\n",
    "            x1 = rect.right()\n",
    "            y1 = rect.bottom()\n",
    "            # get the facial landmarks\n",
    "            landmarks = np.matrix([[p.x, p.y] for p in predictor(frame, rect).parts()])\n",
    "            # get the left eye landmarks\n",
    "            left_eye = landmarks[LEFT_EYE_POINTS]\n",
    "            # get the right eye landmarks\n",
    "            right_eye = landmarks[RIGHT_EYE_POINTS]\n",
    "            # draw contours on the eyes\n",
    "            left_eye_hull = cv2.convexHull(left_eye)\n",
    "            right_eye_hull = cv2.convexHull(right_eye)\n",
    "            #cv2.drawContours(frame, [left_eye_hull], -1, (0, 255, 0), 1) # (image, [contour], all_contours, color, thickness)\n",
    "            #cv2.drawContours(frame, [right_eye_hull], -1, (0, 255, 0), 1)\n",
    "            # compute the EAR for the left eye\n",
    "            ear_left = eye_aspect_ratio(left_eye)\n",
    "            # compute the EAR for the right eye\n",
    "            ear_right = eye_aspect_ratio(right_eye)\n",
    "            # compute the average EAR\n",
    "            ear_avg = (ear_left + ear_right) / 2.0\n",
    "            # detect the eye blink\n",
    "            if ear_avg < EYE_AR_THRESH:\n",
    "                COUNTER += 1\n",
    "            else:\n",
    "                if COUNTER >= EYE_AR_CONSEC_FRAMES:\n",
    "                    TOTAL += 1\n",
    "                    #print(\"Eye blinked\")\n",
    "                COUNTER = 0\n",
    "            if TOTAL == 1:\n",
    "                cv2.putText(frame,\"Avocado\",(30,60),cv2.FONT_HERSHEY_DUPLEX,0.7,(0,255,255))\n",
    "            elif TOTAL == 2:\n",
    "                cv2.putText(frame,\"Avocado\",(30,60),cv2.FONT_HERSHEY_DUPLEX,0.7,(0,255,255))\n",
    "                cv2.putText(frame,\"Sweet Potatao\",(30,90),cv2.FONT_HERSHEY_DUPLEX,0.7,(0,255,255))\n",
    "            elif TOTAL ==3:\n",
    "                cv2.putText(frame,\"Avocado\",(30,60),cv2.FONT_HERSHEY_DUPLEX,0.7,(0,255,255))\n",
    "                cv2.putText(frame,\"Sweet Potatao\",(30,90),cv2.FONT_HERSHEY_DUPLEX,0.7,(0,255,255))\n",
    "                cv2.putText(frame,\"Rice\",(30,120),cv2.FONT_HERSHEY_DUPLEX,0.7,(0,255,255))\n",
    "            elif TOTAL ==4:\n",
    "                cv2.putText(frame,\"Avocado\",(30,60),cv2.FONT_HERSHEY_DUPLEX,0.7,(0,255,255))\n",
    "                cv2.putText(frame,\"Sweet Potatao\",(30,90),cv2.FONT_HERSHEY_DUPLEX,0.7,(0,255,255))\n",
    "                cv2.putText(frame,\"Rice\",(30,120),cv2.FONT_HERSHEY_DUPLEX,0.7,(0,255,255))\n",
    "                cv2.putText(frame,\"Banana\",(30,150),cv2.FONT_HERSHEY_DUPLEX,0.7,(0,255,255))\n",
    "            elif TOTAL ==5:\n",
    "                cv2.putText(frame,\"Avocado\",(30,60),cv2.FONT_HERSHEY_DUPLEX,0.7,(0,255,255))\n",
    "                cv2.putText(frame,\"Sweet Potatao\",(30,90),cv2.FONT_HERSHEY_DUPLEX,0.7,(0,255,255))\n",
    "                cv2.putText(frame,\"Rice\",(30,120),cv2.FONT_HERSHEY_DUPLEX,0.7,(0,255,255))\n",
    "                cv2.putText(frame,\"Banana\",(30,150),cv2.FONT_HERSHEY_DUPLEX,0.7,(0,255,255))\n",
    "                cv2.putText(frame,\"Date\",(30,180),cv2.FONT_HERSHEY_DUPLEX,0.7,(0,255,255))\n",
    "            cv2.putText(frame, \"Blinks{}\".format(TOTAL), (10, 30), cv2.FONT_HERSHEY_DUPLEX, 0.7, (0, 255, 255), 1)\n",
    "            #cv2.putText(frame, \"EAR {}\".format(ear_avg), (10, 60), cv2.FONT_HERSHEY_DUPLEX, 0.7, (0, 255, 255), 1)\n",
    "    \n",
    "        height,width,channels = frame.shape\n",
    "        ret, buffer = cv2.imencode('.jpg', frame)\n",
    "        frame = buffer.tobytes()\n",
    "        yield (b'--frame\\r\\n'\n",
    "               b'Content-Type: image/jpeg\\r\\n\\r\\n' + frame + b'\\r\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/video_feed')\n",
    "def video_feed():\n",
    "    \"\"\"Video streaming route. Put this in the src attribute of an img tag.\"\"\"\n",
    "    return Response(gen_frames(),\n",
    "                    mimetype='multipart/x-mixed-replace; boundary=frame')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [19/Feb/2022 11:18:41] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [19/Feb/2022 11:18:41] \"\u001b[37mGET /video_feed HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    }
   ],
   "source": [
    "@app.route('/')\n",
    "def index():\n",
    "    \"\"\"Video streaming home page.\"\"\"\n",
    "    return render_template('video.html')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error on request:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mini/.local/lib/python3.6/site-packages/werkzeug/serving.py\", line 323, in run_wsgi\n",
      "    execute(self.server.app)\n",
      "  File \"/home/mini/.local/lib/python3.6/site-packages/werkzeug/serving.py\", line 314, in execute\n",
      "    for data in application_iter:\n",
      "  File \"/home/mini/.local/lib/python3.6/site-packages/werkzeug/wsgi.py\", line 506, in __next__\n",
      "    return self._next()\n",
      "  File \"/home/mini/.local/lib/python3.6/site-packages/werkzeug/wrappers/base_response.py\", line 45, in _iter_encoded\n",
      "    for item in iterable:\n",
      "  File \"<ipython-input-57-3dc2fdfc7529>\", line 31, in gen_frames\n",
      "    \n",
      "cv2.error: OpenCV(3.4.2) /io/opencv/modules/imgproc/src/color.hpp:253: error: (-215:Assertion failed) VScn::contains(scn) && VDcn::contains(dcn) && VDepth::contains(depth) in function 'CvtHelper'\n"
     ]
    }
   ],
   "source": [
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread('vata.png')\n",
    "img=cv2.resize(img,(480,640))\n",
    "img_g=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY) #converting to gray scale aS threshold functions for grey image\n",
    "ret,mask= cv2.threshold(img_g,10,255,cv2.THRESH_BINARY) # if thr value is less than 10=> 0, otherwise 255\n",
    "mask_i=cv2.bitwise_not(mask)\n",
    "cv2.imshow(\"t\",mask)\n",
    "cv2.imshow(\"1m\",mask_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(394, 470, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
